{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29ac2314-2d9e-4873-b245-ccefa98c72d7",
   "metadata": {},
   "source": [
    "# WMIR practice lesson on Spacy\n",
    "\n",
    "### Objective\n",
    "Use the Spacy framework to extract relevant information from sentences for enriching the representations.  \n",
    "Train several models and compare them with and without the enriched representations.\n",
    "\n",
    "#### Author\n",
    "Claudiu Daniel Hromei, April 2023.  \n",
    "hromei@ing.uniroma2.it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debf8c5d-291d-443d-b07c-197232764e91",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "[SpaCy](spacy.io) is a free, open-source library for Natural Language Processing (NLP) in Python. It can be used to build information extraction or natural language understanding systems, or to pre-process text for deep learning.  \n",
    "Some Features:\n",
    "- **Tokenization**: Segmenting text into words, punctuations marks etc.\n",
    "- **Part-of-speech (POS) Tagging**: Assigning word types to tokens, like verb or noun.\n",
    "- **Dependency Parsing**: Assigning syntactic dependency labels, describing the relations between individual tokens, like subject or object.\n",
    "- **Lemmatization**: Assigning the base forms of words. For example, the lemma of “was” is “be”, and the lemma of “rats” is “rat”.\n",
    "- **Sentence Boundary Detection (SBD)**: Finding and segmenting individual sentences.\n",
    "- **Named Entity Recognition (NER)**: Labelling named “real-world” objects, like persons, companies or locations.\n",
    "- **Entity Linking (EL)**: Disambiguating textual entities to unique identifiers in a knowledge base.\n",
    "- **Similarity**: Comparing words, text spans and documents and how similar they are to each other.\n",
    "- **Text Classification**: Assigning categories or labels to a whole document, or parts of a document.\n",
    "- **Rule-based Matching**: Finding sequences of tokens based on their texts and linguistic annotations, similar to regular expressions.\n",
    "- **Training**: Updating and improving a statistical model’s predictions.\n",
    "- **Serialization**: Saving objects to files or byte strings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee707a2-9407-4c04-b7fe-9cc9ffcd8a59",
   "metadata": {},
   "source": [
    "# Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a8a4527-39bc-44c9-9850-7d8de84f218e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bb200d9-8f6d-40f0-a094-42937e541184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# option to print all the value of cells in DataFrames\n",
    "pd.set_option(\"max_colwidth\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f646a8f-88b8-4cfe-b831-23e7a704e2a6",
   "metadata": {},
   "source": [
    "### Install spacy and download the english pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26e3cf3c-308e-48a9-a42a-05d4ab8a0278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Downloading spacy-3.5.2-cp39-cp39-win_amd64.whl (12.2 MB)\n",
      "     -------------------------------------- 12.2/12.2 MB 542.3 kB/s eta 0:00:00\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
      "  Downloading spacy_loggers-1.0.4-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\simon\\anaconda3\\lib\\site-packages (from spacy) (63.4.1)\n",
      "Collecting langcodes<4.0.0,>=3.2.0\n",
      "  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "     ------------------------------------ 181.6/181.6 kB 685.6 kB/s eta 0:00:00\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\simon\\anaconda3\\lib\\site-packages (from spacy) (2.28.1)\n",
      "Collecting typer<0.8.0,>=0.3.0\n",
      "  Downloading typer-0.7.0-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\simon\\anaconda3\\lib\\site-packages (from spacy) (4.64.1)\n",
      "Collecting pathy>=0.10.0\n",
      "  Downloading pathy-0.10.1-py3-none-any.whl (48 kB)\n",
      "     -------------------------------------- 48.9/48.9 kB 495.1 kB/s eta 0:00:00\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Downloading cymem-2.0.7-cp39-cp39-win_amd64.whl (30 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Downloading preshed-3.0.8-cp39-cp39-win_amd64.whl (96 kB)\n",
      "     -------------------------------------- 96.8/96.8 kB 460.3 kB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\simon\\anaconda3\\lib\\site-packages (from spacy) (21.3)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\simon\\anaconda3\\lib\\site-packages (from spacy) (1.21.5)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4\n",
      "  Downloading pydantic-1.10.7-cp39-cp39-win_amd64.whl (2.2 MB)\n",
      "     ---------------------------------------- 2.2/2.2 MB 583.6 kB/s eta 0:00:00\n",
      "Collecting thinc<8.2.0,>=8.1.8\n",
      "  Downloading thinc-8.1.9-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 227.0 kB/s eta 0:00:00\n",
      "Collecting wasabi<1.2.0,>=0.9.1\n",
      "  Downloading wasabi-1.1.1-py3-none-any.whl (27 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3\n",
      "  Downloading srsly-2.4.6-cp39-cp39-win_amd64.whl (482 kB)\n",
      "     ------------------------------------ 482.8/482.8 kB 458.4 kB/s eta 0:00:00\n",
      "Requirement already satisfied: jinja2 in c:\\users\\simon\\anaconda3\\lib\\site-packages (from spacy) (2.11.3)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Downloading murmurhash-1.0.9-cp39-cp39-win_amd64.whl (18 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6\n",
      "  Downloading catalogue-2.0.8-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\simon\\anaconda3\\lib\\site-packages (from spacy) (5.2.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\simon\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy) (3.0.9)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\simon\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\simon\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.9.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\simon\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\simon\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\simon\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.11)\n",
      "Collecting blis<0.8.0,>=0.7.8\n",
      "  Downloading blis-0.7.9-cp39-cp39-win_amd64.whl (7.0 MB)\n",
      "     ---------------------------------------- 7.0/7.0 MB 873.7 kB/s eta 0:00:00\n",
      "Collecting confection<1.0.0,>=0.0.1\n",
      "  Downloading confection-0.0.4-py3-none-any.whl (32 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\simon\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.5)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\simon\\anaconda3\\lib\\site-packages (from typer<0.8.0,>=0.3.0->spacy) (8.0.4)\n",
      "Collecting colorama\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\simon\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.0.1)\n",
      "Installing collected packages: cymem, spacy-loggers, spacy-legacy, pydantic, murmurhash, langcodes, colorama, catalogue, blis, wasabi, srsly, preshed, typer, confection, thinc, pathy, spacy\n",
      "  Attempting uninstall: colorama\n",
      "    Found existing installation: colorama 0.4.5\n",
      "    Uninstalling colorama-0.4.5:\n",
      "      Successfully uninstalled colorama-0.4.5\n",
      "Successfully installed blis-0.7.9 catalogue-2.0.8 colorama-0.4.6 confection-0.0.4 cymem-2.0.7 langcodes-3.3.0 murmurhash-1.0.9 pathy-0.10.1 preshed-3.0.8 pydantic-1.10.7 spacy-3.5.2 spacy-legacy-3.0.12 spacy-loggers-1.0.4 srsly-2.4.6 thinc-8.1.9 typer-0.7.0 wasabi-1.1.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "anaconda-project 0.11.1 requires ruamel-yaml, which is not installed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.5.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)\n",
      "     -------------------------------------- 12.8/12.8 MB 280.0 kB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.6.0,>=3.5.0 in c:\\users\\simon\\anaconda3\\lib\\site-packages (from en-core-web-sm==3.5.0) (3.5.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\simon\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (63.4.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\simon\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\simon\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\simon\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (21.3)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\simon\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.7)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\simon\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.1.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\simon\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.64.1)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\simon\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.4)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\simon\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\simon\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.11.3)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in c:\\users\\simon\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.9)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\simon\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (5.2.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\simon\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.4.6)\n",
      "Requirement already satisfied: pathy>=0.10.0 in c:\\users\\simon\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.10.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\simon\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.21.5)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in c:\\users\\simon\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.10.7)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in c:\\users\\simon\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\simon\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.9)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\simon\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.28.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\simon\\anaconda3\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.12)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\simon\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.9)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\simon\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\simon\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2022.9.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\simon\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\simon\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\simon\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.26.11)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\simon\\anaconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\simon\\anaconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\simon\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\simon\\anaconda3\\lib\\site-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\simon\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.1)\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.5.0\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "# install the spacy module\n",
    "!pip install spacy\n",
    "\n",
    "# download the english pipeline here\n",
    "# 'it_core_news_sm' for italian texts\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58bb56fa-93a9-45de-9cfa-678d44d0c033",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7902c303-79c6-4a5f-b0e3-9a20726d300e",
   "metadata": {},
   "source": [
    "# Annotation example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e63395d8-4ea5-47e7-a8f4-ddd5904242d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_string = \"In 1982, Mark drove his car from Los Angeles to Las Vegas until 5 of july\"\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "729983d0-0d1f-483d-b975-0ac74c3d7ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_annotation(input_string):\n",
    "    doc = nlp(input_string)\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        \"id\": [],\n",
    "        \"token\": [],\n",
    "        \"lemma\": [],\n",
    "        \"tag\": [],\n",
    "        \"entity\": [],\n",
    "        \"dependency\": [],\n",
    "        \"head id\": []\n",
    "    })\n",
    "\n",
    "    for sent in doc.sents:\n",
    "        for i, word in enumerate(sent):\n",
    "            if word.head is word:\n",
    "                head_idx = 0\n",
    "            else:\n",
    "                head_idx = doc[i].head.i+1\n",
    "            if head_idx == i + 1:\n",
    "                head_idx = 0\n",
    "\n",
    "            entity_tag = word.ent_type_\n",
    "            if len(entity_tag) == 0:\n",
    "                entity_tag = \"O\"\n",
    "            \n",
    "            word_obj = {\"id\": str(i+1), \"token\": str(word), \"lemma\": word.lemma_, \"tag\": word.tag_, \"entity\": entity_tag,\n",
    "                                    \"dependency\": word.dep_, \"head id\": str(head_idx)}\n",
    "            df = df.append(word_obj, ignore_index=True)\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "85bca778-c678-4b9b-839c-2d8b0797ad95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>token</th>\n",
       "      <th>lemma</th>\n",
       "      <th>tag</th>\n",
       "      <th>entity</th>\n",
       "      <th>dependency</th>\n",
       "      <th>head id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>In</td>\n",
       "      <td>in</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "      <td>prep</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1982</td>\n",
       "      <td>1982</td>\n",
       "      <td>CD</td>\n",
       "      <td>DATE</td>\n",
       "      <td>pobj</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "      <td>punct</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Mark</td>\n",
       "      <td>Mark</td>\n",
       "      <td>NNP</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>drove</td>\n",
       "      <td>drive</td>\n",
       "      <td>VBD</td>\n",
       "      <td>O</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>his</td>\n",
       "      <td>his</td>\n",
       "      <td>PRP$</td>\n",
       "      <td>O</td>\n",
       "      <td>poss</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>car</td>\n",
       "      <td>car</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "      <td>dobj</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>from</td>\n",
       "      <td>from</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "      <td>prep</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Los</td>\n",
       "      <td>Los</td>\n",
       "      <td>NNP</td>\n",
       "      <td>GPE</td>\n",
       "      <td>compound</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Angeles</td>\n",
       "      <td>Angeles</td>\n",
       "      <td>NNP</td>\n",
       "      <td>GPE</td>\n",
       "      <td>pobj</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>to</td>\n",
       "      <td>to</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "      <td>prep</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Las</td>\n",
       "      <td>Las</td>\n",
       "      <td>NNP</td>\n",
       "      <td>GPE</td>\n",
       "      <td>compound</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Vegas</td>\n",
       "      <td>Vegas</td>\n",
       "      <td>NNP</td>\n",
       "      <td>GPE</td>\n",
       "      <td>pobj</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>until</td>\n",
       "      <td>until</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "      <td>prep</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>CD</td>\n",
       "      <td>DATE</td>\n",
       "      <td>pobj</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>DATE</td>\n",
       "      <td>prep</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>july</td>\n",
       "      <td>july</td>\n",
       "      <td>NNP</td>\n",
       "      <td>DATE</td>\n",
       "      <td>pobj</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id    token    lemma   tag  entity dependency head id\n",
       "0    1       In       in    IN       O       prep       5\n",
       "1    2     1982     1982    CD    DATE       pobj       1\n",
       "2    3        ,        ,     ,       O      punct       5\n",
       "3    4     Mark     Mark   NNP  PERSON      nsubj       5\n",
       "4    5    drove    drive   VBD       O       ROOT       0\n",
       "5    6      his      his  PRP$       O       poss       7\n",
       "6    7      car      car    NN       O       dobj       5\n",
       "7    8     from     from    IN       O       prep       5\n",
       "8    9      Los      Los   NNP     GPE   compound      10\n",
       "9   10  Angeles  Angeles   NNP     GPE       pobj       8\n",
       "10  11       to       to    IN       O       prep       5\n",
       "11  12      Las      Las   NNP     GPE   compound      13\n",
       "12  13    Vegas    Vegas   NNP     GPE       pobj      11\n",
       "13  14    until    until    IN       O       prep       5\n",
       "14  15        5        5    CD    DATE       pobj      14\n",
       "15  16       of       of    IN    DATE       prep      15\n",
       "16  17     july     july   NNP    DATE       pobj      16"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_annotation(input_string) #Entity: O-->Not an entity Head id: how many dependency there are in the graph containing that word (how amny arrows to reach the root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f9d53fe4-f3ac-4e61-8b5c-fa263d86a6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_annotation(input_string, style=\"dep\"):\n",
    "    doc = nlp(input_string)\n",
    "    # style can be either \"dep\" or \"ent\"\n",
    "    displacy.render(doc, style=style, jupyter=True, options={\"distance\": 100}) #distance default 140, visualization metric\n",
    "    #Jupyter=true --> use no server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6301d0c6-9f73-491c-84dc-c93f39eb8d3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"888470b551ca4674b489036bdea75aa7-0\" class=\"displacy\" width=\"1650\" height=\"387.0\" direction=\"ltr\" style=\"max-width: none; height: 387.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"297.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">In</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"297.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"150\">1982,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"150\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"297.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"250\">Mark</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"250\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"297.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"350\">drove</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"350\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"297.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"450\">his</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"450\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"297.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"550\">car</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"550\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"297.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"650\">from</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"650\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"297.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">Los</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"297.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"850\">Angeles</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"850\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"297.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"950\">to</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"950\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"297.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1050\">Las</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1050\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"297.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1150\">Vegas</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1150\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"297.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1250\">until</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1250\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"297.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1350\">5</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1350\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"297.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">of</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"297.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1550\">july</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1550\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-888470b551ca4674b489036bdea75aa7-0-0\" stroke-width=\"2px\" d=\"M70,252.0 C70,152.0 335.0,152.0 335.0,252.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-888470b551ca4674b489036bdea75aa7-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,254.0 L62,242.0 78,242.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-888470b551ca4674b489036bdea75aa7-0-1\" stroke-width=\"2px\" d=\"M70,252.0 C70,202.0 130.0,202.0 130.0,252.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-888470b551ca4674b489036bdea75aa7-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M130.0,254.0 L138.0,242.0 122.0,242.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-888470b551ca4674b489036bdea75aa7-0-2\" stroke-width=\"2px\" d=\"M270,252.0 C270,202.0 330.0,202.0 330.0,252.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-888470b551ca4674b489036bdea75aa7-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M270,254.0 L262,242.0 278,242.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-888470b551ca4674b489036bdea75aa7-0-3\" stroke-width=\"2px\" d=\"M470,252.0 C470,202.0 530.0,202.0 530.0,252.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-888470b551ca4674b489036bdea75aa7-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">poss</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M470,254.0 L462,242.0 478,242.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-888470b551ca4674b489036bdea75aa7-0-4\" stroke-width=\"2px\" d=\"M370,252.0 C370,152.0 535.0,152.0 535.0,252.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-888470b551ca4674b489036bdea75aa7-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M535.0,254.0 L543.0,242.0 527.0,242.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-888470b551ca4674b489036bdea75aa7-0-5\" stroke-width=\"2px\" d=\"M370,252.0 C370,102.0 640.0,102.0 640.0,252.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-888470b551ca4674b489036bdea75aa7-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M640.0,254.0 L648.0,242.0 632.0,242.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-888470b551ca4674b489036bdea75aa7-0-6\" stroke-width=\"2px\" d=\"M770,252.0 C770,202.0 830.0,202.0 830.0,252.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-888470b551ca4674b489036bdea75aa7-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M770,254.0 L762,242.0 778,242.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-888470b551ca4674b489036bdea75aa7-0-7\" stroke-width=\"2px\" d=\"M670,252.0 C670,152.0 835.0,152.0 835.0,252.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-888470b551ca4674b489036bdea75aa7-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M835.0,254.0 L843.0,242.0 827.0,242.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-888470b551ca4674b489036bdea75aa7-0-8\" stroke-width=\"2px\" d=\"M370,252.0 C370,52.0 945.0,52.0 945.0,252.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-888470b551ca4674b489036bdea75aa7-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M945.0,254.0 L953.0,242.0 937.0,242.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-888470b551ca4674b489036bdea75aa7-0-9\" stroke-width=\"2px\" d=\"M1070,252.0 C1070,202.0 1130.0,202.0 1130.0,252.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-888470b551ca4674b489036bdea75aa7-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1070,254.0 L1062,242.0 1078,242.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-888470b551ca4674b489036bdea75aa7-0-10\" stroke-width=\"2px\" d=\"M970,252.0 C970,152.0 1135.0,152.0 1135.0,252.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-888470b551ca4674b489036bdea75aa7-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1135.0,254.0 L1143.0,242.0 1127.0,242.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-888470b551ca4674b489036bdea75aa7-0-11\" stroke-width=\"2px\" d=\"M370,252.0 C370,2.0 1250.0,2.0 1250.0,252.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-888470b551ca4674b489036bdea75aa7-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1250.0,254.0 L1258.0,242.0 1242.0,242.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-888470b551ca4674b489036bdea75aa7-0-12\" stroke-width=\"2px\" d=\"M1270,252.0 C1270,202.0 1330.0,202.0 1330.0,252.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-888470b551ca4674b489036bdea75aa7-0-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1330.0,254.0 L1338.0,242.0 1322.0,242.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-888470b551ca4674b489036bdea75aa7-0-13\" stroke-width=\"2px\" d=\"M1370,252.0 C1370,202.0 1430.0,202.0 1430.0,252.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-888470b551ca4674b489036bdea75aa7-0-13\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1430.0,254.0 L1438.0,242.0 1422.0,242.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-888470b551ca4674b489036bdea75aa7-0-14\" stroke-width=\"2px\" d=\"M1470,252.0 C1470,202.0 1530.0,202.0 1530.0,252.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-888470b551ca4674b489036bdea75aa7-0-14\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1530.0,254.0 L1538.0,242.0 1522.0,242.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_annotation(input_string, style=\"dep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a66b00a8-caf7-4985-beeb-edb92c0333e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">In \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    1982\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Mark\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " drove his car from \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Los Angeles\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " to \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Las Vegas\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " until \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    5 of july\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_annotation(input_string, style=\"ent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "66e4a99a-7c40-496e-ac12-40d529769201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"spans\" style=\"line-height: 2.5; direction: ltr\">In 1982 , Mark drove his car from Los Angeles to Las Vegas until 5 of july </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_annotation(input_string, style=\"span\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6c3461-ed02-406d-93d1-03e1920ab717",
   "metadata": {},
   "source": [
    "# Information extraction\n",
    "\n",
    "Get information about a particular word in a given string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3ef176e6-7cee-4d08-83de-69c5f8e822d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_annotation(input_string, word_string):\n",
    "    doc = nlp(input_string)\n",
    "    \n",
    "    words = []\n",
    "    for sent in doc.sents:\n",
    "        for i, word in enumerate(sent):\n",
    "            if word.head is word:\n",
    "                head_idx = 0\n",
    "            else:\n",
    "                head_idx = doc[i].head.i+1\n",
    "            if head_idx == i + 1:\n",
    "                head_idx = 0\n",
    "\n",
    "            entity_tag = word.ent_type_\n",
    "            if len(entity_tag) == 0:\n",
    "                entity_tag = \"O\"\n",
    "            \n",
    "            word_obj = {\"id\": i+1, \"token\": str(word), \"lemma\": word.lemma_, \"tag\": word.tag_, \"entity\": entity_tag,\n",
    "                                    \"dependency\": word.dep_, \"head id\": head_idx}\n",
    "            words.append(word_obj)\n",
    "    \n",
    "    for word in words:\n",
    "        if word[\"token\"] == word_string:\n",
    "            return word\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c0ebd5d8-a587-45b7-838c-ffaef5f533c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 4, 'token': 'Mark', 'lemma': 'Mark', 'tag': 'NNP', 'entity': 'PERSON', 'dependency': 'nsubj', 'head id': 5}\n",
      "{'id': 2, 'token': '1982', 'lemma': '1982', 'tag': 'CD', 'entity': 'DATE', 'dependency': 'pobj', 'head id': 1}\n"
     ]
    }
   ],
   "source": [
    "print(get_word_annotation(input_string, \"Mark\"))\n",
    "print(get_word_annotation(input_string, \"1982\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7a0806-71bb-43a3-ae19-e23877b91197",
   "metadata": {},
   "source": [
    "### Exercise 1: Search for relations\n",
    "\n",
    "Define a method that takes in input a sentence (`input_string`) and the name of a relation (`relation_string`), parses with spacy the input and returns the words (the `objects`! not the strings) involved in the relation. If the relation is not present, return an empty array.\n",
    "\n",
    "```\n",
    "def search_relation(input_string, relation_string):\n",
    "    return word_obj_list\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e917dee3-a374-48e3-a561-8fb39e8e2e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_relation(input_string, relation_String):\n",
    "    doc = nlp(input_string)\n",
    "    \n",
    "    words = []\n",
    "    ret = []\n",
    "    for sent in doc.sents:\n",
    "        for i, word in enumerate(sent):\n",
    "            if word.head is word:\n",
    "                head_idx = 0\n",
    "            else:\n",
    "                head_idx = doc[i].head.i+1\n",
    "            if head_idx == i + 1:\n",
    "                head_idx = 0\n",
    "\n",
    "            entity_tag = word.ent_type_\n",
    "            if len(entity_tag) == 0:\n",
    "                entity_tag = \"O\"\n",
    "            \n",
    "            word_obj = {\"id\": i+1, \"token\": str(word), \"lemma\": word.lemma_, \"tag\": word.tag_, \"entity\": entity_tag,\n",
    "                                    \"dependency\": word.dep_, \"head id\": head_idx}\n",
    "            words.append(word_obj)\n",
    "    \n",
    "    for word in words:\n",
    "        if word[\"dependency\"] == relation_String:\n",
    "            ret.append(word)\n",
    "    if(ret == []):\n",
    "        ret = None\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c4df3c10-f389-4c7a-b4ab-b5e000b691d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 1,\n",
       "  'token': 'In',\n",
       "  'lemma': 'in',\n",
       "  'tag': 'IN',\n",
       "  'entity': 'O',\n",
       "  'dependency': 'prep',\n",
       "  'head id': 5},\n",
       " {'id': 8,\n",
       "  'token': 'from',\n",
       "  'lemma': 'from',\n",
       "  'tag': 'IN',\n",
       "  'entity': 'O',\n",
       "  'dependency': 'prep',\n",
       "  'head id': 5},\n",
       " {'id': 11,\n",
       "  'token': 'to',\n",
       "  'lemma': 'to',\n",
       "  'tag': 'IN',\n",
       "  'entity': 'O',\n",
       "  'dependency': 'prep',\n",
       "  'head id': 5},\n",
       " {'id': 14,\n",
       "  'token': 'until',\n",
       "  'lemma': 'until',\n",
       "  'tag': 'IN',\n",
       "  'entity': 'O',\n",
       "  'dependency': 'prep',\n",
       "  'head id': 5},\n",
       " {'id': 16,\n",
       "  'token': 'of',\n",
       "  'lemma': 'of',\n",
       "  'tag': 'IN',\n",
       "  'entity': 'DATE',\n",
       "  'dependency': 'prep',\n",
       "  'head id': 15}]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_word_relation(input_string,\"prep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "162b975c-a0fb-4f55-a9e1-e66ff2ee7f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_relation_2(input_string, relation_String):\n",
    "    doc = nlp(input_string)\n",
    "    \n",
    "    words = []\n",
    "    ret = []\n",
    "    for sent in doc.sents:\n",
    "        for i, word in enumerate(sent):\n",
    "            if word.head is word:\n",
    "                head_idx = 0\n",
    "            else:\n",
    "                head_idx = doc[i].head.i+1\n",
    "            if head_idx == i + 1:\n",
    "                head_idx = 0\n",
    "\n",
    "            entity_tag = word.ent_type_\n",
    "            if len(entity_tag) == 0:\n",
    "                entity_tag = \"O\"\n",
    "            \n",
    "            word_obj = {\"id\": i+1, \"token\": str(word), \"lemma\": word.lemma_, \"tag\": word.tag_, \"entity\": entity_tag,\n",
    "                                    \"dependency\": word.dep_, \"head id\": head_idx}\n",
    "            words.append(word_obj)\n",
    "    \n",
    "    for word in words:\n",
    "        if word[\"dependency\"] == relation_String:\n",
    "            l = []\n",
    "            for w in words:\n",
    "                if(word[\"head id\"] == w[\"id\"]):\n",
    "                    l.append(w[\"lemma\"])\n",
    "                    break\n",
    "            l.append(word[\"lemma\"])\n",
    "            l.append(word[\"dependency\"])\n",
    "            ret.append(l)\n",
    "            \n",
    "    if(not ret):\n",
    "        ret = None\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "a57a65ff-c08e-44e2-b25f-bd455a3a1447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Angeles', 'Los', 'compound'], ['Vegas', 'Las', 'compound']]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_word_relation_2(input_string,\"compound\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2a0c5ffe-c334-4a2b-8c31-43235ec438d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>token</th>\n",
       "      <th>lemma</th>\n",
       "      <th>tag</th>\n",
       "      <th>entity</th>\n",
       "      <th>dependency</th>\n",
       "      <th>head id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>In</td>\n",
       "      <td>in</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "      <td>prep</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1982</td>\n",
       "      <td>1982</td>\n",
       "      <td>CD</td>\n",
       "      <td>DATE</td>\n",
       "      <td>pobj</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "      <td>punct</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Mark</td>\n",
       "      <td>Mark</td>\n",
       "      <td>NNP</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>drove</td>\n",
       "      <td>drive</td>\n",
       "      <td>VBD</td>\n",
       "      <td>O</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>his</td>\n",
       "      <td>his</td>\n",
       "      <td>PRP$</td>\n",
       "      <td>O</td>\n",
       "      <td>poss</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>car</td>\n",
       "      <td>car</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "      <td>dobj</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>from</td>\n",
       "      <td>from</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "      <td>prep</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Los</td>\n",
       "      <td>Los</td>\n",
       "      <td>NNP</td>\n",
       "      <td>GPE</td>\n",
       "      <td>compound</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Angeles</td>\n",
       "      <td>Angeles</td>\n",
       "      <td>NNP</td>\n",
       "      <td>GPE</td>\n",
       "      <td>pobj</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>to</td>\n",
       "      <td>to</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "      <td>prep</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Las</td>\n",
       "      <td>Las</td>\n",
       "      <td>NNP</td>\n",
       "      <td>GPE</td>\n",
       "      <td>compound</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Vegas</td>\n",
       "      <td>Vegas</td>\n",
       "      <td>NNP</td>\n",
       "      <td>GPE</td>\n",
       "      <td>pobj</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>until</td>\n",
       "      <td>until</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "      <td>prep</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>CD</td>\n",
       "      <td>DATE</td>\n",
       "      <td>pobj</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>DATE</td>\n",
       "      <td>prep</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>july</td>\n",
       "      <td>july</td>\n",
       "      <td>NNP</td>\n",
       "      <td>DATE</td>\n",
       "      <td>pobj</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id    token    lemma   tag  entity dependency head id\n",
       "0    1       In       in    IN       O       prep       5\n",
       "1    2     1982     1982    CD    DATE       pobj       1\n",
       "2    3        ,        ,     ,       O      punct       5\n",
       "3    4     Mark     Mark   NNP  PERSON      nsubj       5\n",
       "4    5    drove    drive   VBD       O       ROOT       0\n",
       "5    6      his      his  PRP$       O       poss       7\n",
       "6    7      car      car    NN       O       dobj       5\n",
       "7    8     from     from    IN       O       prep       5\n",
       "8    9      Los      Los   NNP     GPE   compound      10\n",
       "9   10  Angeles  Angeles   NNP     GPE       pobj       8\n",
       "10  11       to       to    IN       O       prep       5\n",
       "11  12      Las      Las   NNP     GPE   compound      13\n",
       "12  13    Vegas    Vegas   NNP     GPE       pobj      11\n",
       "13  14    until    until    IN       O       prep       5\n",
       "14  15        5        5    CD    DATE       pobj      14\n",
       "15  16       of       of    IN    DATE       prep      15\n",
       "16  17     july     july   NNP    DATE       pobj      16"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_annotation(input_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca3817d-97b4-452e-9928-df51d9d4122b",
   "metadata": {},
   "source": [
    "### Exercise 2: Search for entities\n",
    "\n",
    "Define a method that takes in input a sentence (`input_string`) and the name of an entity type (`entity_type_string`), parses with spacy the input and returns the words (the `objects`! not the strings) described by that entity. If the entity type is not present, return an empty array.\n",
    "\n",
    "```\n",
    "def search_entity(input_string, entity_type_string):\n",
    "    return word_obj_list\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "297e77e5-a0b6-49d6-a34e-e6924e1e50a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_entity(input_string, entity_type_string):\n",
    "    doc = nlp(input_string)\n",
    "    \n",
    "    words = []\n",
    "    ret = []\n",
    "    for sent in doc.sents:\n",
    "        for i, word in enumerate(sent):\n",
    "            if word.head is word:\n",
    "                head_idx = 0\n",
    "            else:\n",
    "                head_idx = doc[i].head.i+1\n",
    "            if head_idx == i + 1:\n",
    "                head_idx = 0\n",
    "\n",
    "            entity_tag = word.ent_type_\n",
    "            if len(entity_tag) == 0:\n",
    "                entity_tag = \"O\"\n",
    "            \n",
    "            word_obj = {\"id\": i+1, \"token\": str(word), \"lemma\": word.lemma_, \"tag\": word.tag_, \"entity\": entity_tag,\n",
    "                                    \"dependency\": word.dep_, \"head id\": head_idx}\n",
    "            words.append(word_obj)\n",
    "    \n",
    "    i=0\n",
    "    while(i<len(words)):\n",
    "        res = []\n",
    "        while(i<len(words) and words[i][\"entity\"] == entity_type_string):\n",
    "            res.append(words[i][\"lemma\"])\n",
    "            i=i+1\n",
    "        if(res):\n",
    "            ret.append(\" \".join(res))\n",
    "        i=i+1\n",
    "            \n",
    "    if(not ret):\n",
    "        ret = None\n",
    "                          \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "56ed30fd-017d-4cef-ba5c-55baba6961aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Los Angeles', 'Las Vegas']"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_entity(input_string,\"GPE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "4ff87f58-b515-4540-ac08-b9675c623076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">In \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    1982\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Mark\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " drove his car from \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Los Angeles\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " to \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Las Vegas\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " until \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    5 of july\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_annotation(input_string, style=\"ent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "f9a2543d-32a9-4cb5-85ab-9f543f2efde2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1982', '5 of july']"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_entity(input_string,\"DATE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0f92dc-9e0c-4cbe-838e-4ab916ded271",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
